{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigment: Neural network basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soft deadline: 16.09.18 at 23.59\n",
    "\n",
    "Hard deadline: 18.09.18 at 23.59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this task I intentionally provide no boilerplate code, because very puprpose of this task is getting you comforatable with basic code template for desiging NNs in pytorch. I higly recommend you to revisit all the last seminar materials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task\n",
    "\n",
    "* Implement simple **fully-convolutional** neural architecture for classification. Make sure it is small enought to run on your home machine.\n",
    "* Provide dataset visulization.\n",
    "* Provide train/test split and validation\n",
    "\n",
    "#### Requirements\n",
    "\n",
    "* Architecture should derive from `torch.nn.Module`\n",
    "* Use `torch.utils.data.Dataset` and `torch.utils.data.DataLoader`. But if you manage co simplify this step using dataset `torchivision`, I will only encourage you.\n",
    "* Implement at least one data transformer, but make sure it is useful for classification task.\n",
    "* Use FashionMNIST dataset https://github.com/zalandoresearch/fashion-mnist\n",
    "* Make sure you can fix random seed for all components of your code to make experiments reproducible\n",
    "* Since you architecure should be fully-convolutional, make sure it does not depend on input size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.461066 acc=0.094\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.952362 acc=0.688\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.573722 acc=0.906\n",
      "\n",
      "Test set: Average loss: 0.0106, Accuracy: 8000/10000 (80%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.656304 acc=0.859\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.707872 acc=0.781\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.493176 acc=0.859\n",
      "\n",
      "Test set: Average loss: 0.0081, Accuracy: 8291/10000 (83%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.776980 acc=0.734\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.624430 acc=0.781\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.479863 acc=0.844\n",
      "\n",
      "Test set: Average loss: 0.0074, Accuracy: 8389/10000 (84%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.428938 acc=0.875\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.461656 acc=0.844\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.371216 acc=0.891\n",
      "\n",
      "Test set: Average loss: 0.0070, Accuracy: 8420/10000 (84%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.848792 acc=0.734\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.461418 acc=0.859\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.282681 acc=0.891\n",
      "\n",
      "Test set: Average loss: 0.0070, Accuracy: 8437/10000 (84%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.548712 acc=0.797\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.399410 acc=0.891\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.352265 acc=0.875\n",
      "\n",
      "Test set: Average loss: 0.0067, Accuracy: 8541/10000 (85%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.375654 acc=0.859\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.441225 acc=0.812\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.358512 acc=0.906\n",
      "\n",
      "Test set: Average loss: 0.0064, Accuracy: 8615/10000 (86%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.345895 acc=0.875\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.400714 acc=0.859\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.310626 acc=0.906\n",
      "\n",
      "Test set: Average loss: 0.0064, Accuracy: 8557/10000 (86%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.552752 acc=0.750\n",
      "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.402951 acc=0.875\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.497708 acc=0.875\n",
      "\n",
      "Test set: Average loss: 0.0060, Accuracy: 8636/10000 (86%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.243599 acc=0.906\n",
      "Train Epoch: 10 [28800/60000 (48%)]\tLoss: 0.395267 acc=0.844\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.395765 acc=0.875\n",
      "\n",
      "Test set: Average loss: 0.0060, Accuracy: 8643/10000 (86%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.344646 acc=0.844\n",
      "Train Epoch: 11 [28800/60000 (48%)]\tLoss: 0.352456 acc=0.844\n",
      "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.547314 acc=0.828\n",
      "\n",
      "Test set: Average loss: 0.0058, Accuracy: 8661/10000 (87%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.546160 acc=0.781\n",
      "Train Epoch: 12 [28800/60000 (48%)]\tLoss: 0.361907 acc=0.875\n",
      "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 0.377691 acc=0.844\n",
      "\n",
      "Test set: Average loss: 0.0058, Accuracy: 8692/10000 (87%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.229053 acc=0.922\n",
      "Train Epoch: 13 [28800/60000 (48%)]\tLoss: 0.208369 acc=0.938\n",
      "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.341680 acc=0.906\n",
      "\n",
      "Test set: Average loss: 0.0056, Accuracy: 8741/10000 (87%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.392873 acc=0.859\n",
      "Train Epoch: 14 [28800/60000 (48%)]\tLoss: 0.562880 acc=0.844\n",
      "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.461492 acc=0.844\n",
      "\n",
      "Test set: Average loss: 0.0057, Accuracy: 8732/10000 (87%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.269842 acc=0.906\n",
      "Train Epoch: 15 [28800/60000 (48%)]\tLoss: 0.407657 acc=0.844\n",
      "Train Epoch: 15 [57600/60000 (96%)]\tLoss: 0.558815 acc=0.828\n",
      "\n",
      "Test set: Average loss: 0.0055, Accuracy: 8764/10000 (88%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.476985 acc=0.859\n",
      "Train Epoch: 16 [28800/60000 (48%)]\tLoss: 0.419195 acc=0.828\n",
      "Train Epoch: 16 [57600/60000 (96%)]\tLoss: 0.271743 acc=0.922\n",
      "\n",
      "Test set: Average loss: 0.0055, Accuracy: 8750/10000 (88%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.312896 acc=0.891\n",
      "Train Epoch: 17 [28800/60000 (48%)]\tLoss: 0.508779 acc=0.812\n",
      "Train Epoch: 17 [57600/60000 (96%)]\tLoss: 0.411861 acc=0.859\n",
      "\n",
      "Test set: Average loss: 0.0061, Accuracy: 8642/10000 (86%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.396350 acc=0.922\n",
      "Train Epoch: 18 [28800/60000 (48%)]\tLoss: 0.365371 acc=0.891\n",
      "Train Epoch: 18 [57600/60000 (96%)]\tLoss: 0.519400 acc=0.828\n",
      "\n",
      "Test set: Average loss: 0.0054, Accuracy: 8828/10000 (88%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.421820 acc=0.875\n",
      "Train Epoch: 19 [28800/60000 (48%)]\tLoss: 0.236810 acc=0.938\n",
      "Train Epoch: 19 [57600/60000 (96%)]\tLoss: 0.413441 acc=0.891\n",
      "\n",
      "Test set: Average loss: 0.0055, Accuracy: 8759/10000 (88%)\n",
      "\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.217369 acc=0.922\n",
      "Train Epoch: 20 [28800/60000 (48%)]\tLoss: 0.369431 acc=0.859\n",
      "Train Epoch: 20 [57600/60000 (96%)]\tLoss: 0.386198 acc=0.906\n",
      "\n",
      "Test set: Average loss: 0.0058, Accuracy: 8710/10000 (87%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "torch.backends.cudnn.deterministic=True\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(1, 16, 3),\n",
    "                                   #  nn.MaxPool2d(3, stride=1)\n",
    "                                   nn.BatchNorm2d(16),\n",
    "                                   nn.LeakyReLU())\n",
    "\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(16, 32, 3),\n",
    "                                  # nn.MaxPool2d(3, stride=1)\n",
    "                                   nn.BatchNorm2d(32),\n",
    "                                   nn.LeakyReLU())\n",
    "        \n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(32, 64, 3),\n",
    "                                   nn.BatchNorm2d(64),\n",
    "                                   nn.LeakyReLU(),\n",
    "                                   nn.MaxPool2d(2))\n",
    "        \n",
    "        self.conv4 = nn.Sequential(nn.Conv2d(64, 16, 3),\n",
    "                                   nn.BatchNorm2d(16),\n",
    "                                   nn.LeakyReLU(),\n",
    "                                   nn.MaxPool2d(2))\n",
    "\n",
    "        self.conv5 = nn.Sequential(nn.Conv2d(16, 10, 3),\n",
    "                                   nn.BatchNorm2d(10),\n",
    "                                   nn.LeakyReLU(),\n",
    "                                   nn.MaxPool2d(2))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "\n",
    "        output = F.max_pool2d(x, kernel_size=x.size()[2:])\n",
    "        return output\n",
    "\n",
    "def one_hot(labels, num_classes=10):\n",
    "\n",
    "    y = torch.eye(num_classes, dtype=torch.long) \n",
    "    return y[labels] \n",
    "\n",
    "\n",
    "def train(epoch_num, model, optimizer, loss_func, train_loader):\n",
    "    model.train()\n",
    "    for batch_idx, (x, y) in enumerate(train_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        x, y = Variable(x), Variable(y)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_ = model(x)\n",
    "        y_ = y_.squeeze(3)\n",
    "        y_ = y_.squeeze(2)\n",
    "\n",
    "        loss = loss_func(y_, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred = y_.data.max(1)[1]\n",
    "        correct = pred.eq(y.data).cpu().sum()\n",
    "\n",
    "        acc = float(correct) / len(pred)\n",
    "        \n",
    "        if batch_idx % 450 == 0:\n",
    "            print(f'Train Epoch: {epoch_num+1} [{ batch_idx * len(x)}/{len(train_loader.dataset)}'\n",
    "                  f' ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: { loss.item():.6f} acc={acc:.3f}')\n",
    "            \n",
    "def test(epoch_num, model, loss_func, test_loader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            y_ = model(x)\n",
    "            y_ = y_.squeeze(3)\n",
    "            y_ = y_.squeeze(2)\n",
    "            \n",
    "            test_loss += loss_func(y_, y).item()\n",
    "            pred = y_.data.max(1)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(y.data).cpu().sum()\n",
    "\n",
    "        acc = 100. * float(correct) / len(test_loader.dataset)\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{ len(test_loader.dataset)}'\n",
    "              f' ({acc:.0f}%)\\n')\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    n_epoches = 20\n",
    "    model = MyModel().to(device)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        datasets.FashionMNIST(root=\".\", train=True, download=True, transform=transforms.Compose([\n",
    "            \n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomAffine(20),\n",
    "            transforms.RandomCrop(26),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])),\n",
    "        batch_size=64, shuffle=True, num_workers=4)\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        datasets.FashionMNIST(root='.', train=False, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,)),\n",
    "        ])), \n",
    "        batch_size=64, shuffle=True, num_workers=4)\n",
    "\n",
    "    for i_epoch in range(n_epoches):\n",
    "        train(i_epoch, model, optimizer, loss_func, train_loader)\n",
    "        test(i_epoch,model,loss_func, test_loader)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
